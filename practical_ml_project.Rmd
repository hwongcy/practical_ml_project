---
title: "<span style='font-size: 48px'>Practical_ML_Project</span>"
author: "<span style='font-size: 24px'>Henry CY Wong</span>"
date: "<span style='font-size: 24px'>2021-04-10</span>"
output:
    html_document:
            css: style.css
            keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

&nbsp;
&nbsp;

## 1. Introduction

With using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit*, etc., a large amount of data about personal activities could be collected for health improvement and exerise patterns/behavior identification, etc. However, it is common to focus on how *much* of  a particular activity people do instead of how *well* they do. Thus, the objective of this project is to predict the manner in which they did the exercise by using the **classe** variable in the given training dataset and to use the prediction model to predict 20 different test cases in the given testing datasets.

&nbsp;
&nbsp;

## 2. Data Preparation and Cleaning

The datasets will be loaded as shown below:

```{r load_dataset}
dataset_train <- read.csv('./pml-training.csv', header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
dataset_validate <- read.csv('./pml-testing.csv', header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
```

The dimension of the dataset is:

```{r show_dim}
dim(dataset_train)
```

The columns of the training dataset are:

```{r show_col}
names(dataset_train)
```

Columns with *all* values **NA** will be removed as shown below.

```{r remove_col_with_na}
data_train <- dataset_train[,colSums(is.na(dataset_train)) == 0]
data_validate <- dataset_validate[,colSums(is.na(dataset_validate)) == 0]
```

The first 7 columns will be removed as shown below because they are not related to the model building.

```{r remove_1st_7_col}
data_train <- data_train[,-c(1:7)]
data_validate <- data_validate[,-c(1:7)]
```

Dataset for model building/training after data cleaning becomes:

```{r show_data}
str(data_train)
```

&nbsp;
&nbsp;

## 3. Model Building

The library **caret** will be loaded as shown below for model building:

```{r load_lib}
library("caret")
```

&nbsp;

The original train dataset, **data_train**, will be partitioned into 2 datasets which are train dataset and test dataset, respectively, for model training and testing as shown below:

```{r data_partition}
set.seed(20210101)
samples_partition <- createDataPartition(y=data_train$classe, p=0.75, list=FALSE)
samples_train <- data_train[samples_partition,]
samples_test <- data_train[-samples_partition,]
```

&nbsp;

Models Decision Tree, Generalized Boosted Regression Model and Random Forest are considered and 3-fold cross validation will be used.

```{r set_3fold_cv}
train_control <- trainControl(method = "cv", number = 3, verboseIter = FALSE)
```

&nbsp;

### 3.1 Decision Tree

The Decision Tree model will be trained, predicted and tested as follows:

```{r train_dt, cache=TRUE, results="hide"}
model_dt <- train(classe ~ ., data = samples_train, trControl = train_control, tuneLength = 5, method = "rpart")
predict_dt <- predict(model_dt, newdata = samples_test)
cm_dt <- confusionMatrix(predict_dt, factor(samples_test$classe))
```
```{r showw_cm_dt}
cm_dt
```

&nbsp;

### 3.2 Generalized Boosted Regression Model

The Generalized Boosted Regression Model will be trained, predicted and tested as follows:

```{r train_gbm, cache=TRUE, results="hide"}
model_gbm <- train(classe ~ ., data = samples_train, trControl = train_control, tuneLength = 5, method = "gbm")
predict_gbm <- predict(model_gbm, newdata = samples_test)
cm_gbm <- confusionMatrix(predict_gbm, factor(samples_test$classe))
```
```{r show_cm_gbm}
cm_gbm
```

&nbsp;

### 3.3 Random Forest

The Random Forest will be trained, predicted and tested as follows:

```{r train_rf, cache=TRUE, results="hide"}
model_rf <- train(classe ~ ., data = samples_train, trControl = train_control, tuneLength = 5, method = "rf")
predict_rf <- predict(model_rf, newdata = samples_test)
cm_rf <- confusionMatrix(predict_rf, factor(samples_test$classe))
```
```{r show_cm_rf}
cm_rf
```

&nbsp;

### 3.4 Comparison of the Model's Accuracy

```{r compare_results}
model_accuracy <- data.frame(Model = c("Decision Tree", "Generalized Boosted Regression Model", "Random Forest"), 
                             Accuracy = rbind(cm_dt$overall[1], cm_gbm$overall[1], cm_rf$overall[1]))
print(model_accuracy)
```


&nbsp;
&nbsp;

## 4. Conclusion

According to the accuracy of the confusion matrices between Decision Tree, Generalized Boosted Regression Model and Random Forest, it is found that the accuracy of Random Forest is the highest which is 0.9967 (95% CI: (0.9947, 0.9981)) and corresponding expected out-of-samples error is 0.0033. Therefore, Random Forest will be chosen as the prediction model.

With using Random Forests, the prediction of the given testing dataset **pml-testing.csv** is

```{r predict_validate_dataset}
predict_validate <- predict(model_rf, newdata = data_validate)
predict_validate
```

&nbsp;
&nbsp;

## 5. Appendix

### 5.1 Plot for Decision Tree

```{r plot_model_dt}
plot(model_dt)
```

&nbsp;

### 5.2 Plot for Generalized Boosted Regression Model

```{r plot_model_gbm}
plot(model_gbm)
```

&nbsp;

### 5.3 Plot for Random Forest

```{r plot_model_rf}
plot(model_rf)
```